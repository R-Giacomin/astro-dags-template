from __future__ import annotations
from airflow.decorators import dag, task
from airflow.operators.python import get_current_context
import pendulum
import requests
import pandas as pd
from airflow.providers.google.cloud.hooks.bigquery import BigQueryHook

# ConfiguraÃ§Ãµes
GCP_PROJECT = "gen-lang-client-0010767843" 
BQ_DATASET  = "fda"     
BQ_TABLE    = "fda_aspirin_events"
BQ_LOCATION = "US"      
GCP_CONN_ID = "google_cloud_default"

API_BASE_URL = "https://api.fda.gov/drug/event.json"
API_LIMIT = 50  # Reduzido para evitar sobrecarga

DEFAULT_ARGS = {
    "email_on_failure": True,
    "owner": "Generated by Gemini",
}

def extract_specific_fields(record):
    """
    Extrai os campos especÃ­ficos de cada registro da FDA.
    """
    try:
        # Campos bÃ¡sicos
        safetyreportid = record.get('safetyreportid')
        receivedate = record.get('receivedate')
        serious = record.get('serious')
        
        # Campos aninhados - paciente
        patient_sex = None
        if 'patient' in record and record['patient']:
            patient_sex = record['patient'].get('patientsex')
        
        # Campos aninhados - reaÃ§Ãµes (pegar a primeira reaÃ§Ã£o)
        reactionmeddrapt = None
        if 'patient' in record and record['patient']:
            if 'reaction' in record['patient'] and record['patient']['reaction']:
                first_reaction = record['patient']['reaction'][0]
                reactionmeddrapt = first_reaction.get('reactionmeddrapt')
        
        return {
            'safetyreportid': safetyreportid,
            'receivedate': receivedate,
            'serious': serious,
            'patient_patientsex': patient_sex,
            'reactionmeddrapt': reactionmeddrapt
        }
    except Exception as e:
        print(f"âŒ Erro ao extrair campos do registro: {e}")
        return None

@task
def fetch_and_load_fda_data():
    """
    Busca dados de eventos adversos para Aspirin - UM DIA POR VEZ.
    """
    ctx = get_current_context()

    # 1. Usar APENAS UM DIA especÃ­fico - 01/09/2025
    target_date = pendulum.datetime(2025, 9, 1, tz="UTC")
    
    # Formato de data: AAAAMMDD (mesmo dia para inÃ­cio e fim)
    start_date = target_date.strftime('%Y%m%d')
    end_date = target_date.strftime('%Y%m%d')

    print(f"ğŸ” Buscando dados do Aspirin para UM DIA: {start_date}")

    all_results = []
    skip = 0
    max_records = 500  # Limite mÃ¡ximo

    # 2. Loop de PaginaÃ§Ã£o para um Ãºnico dia
    while True:
        if skip >= max_records:
            print(f"ğŸ“Š Atingido o limite de {max_records} registros.")
            break

        # Query para UM DIA especÃ­fico
        search_query = f'patient.drug.medicinalproduct:"aspirin"+AND+receivedate:[{start_date}+TO+{end_date}]'
        
        params = {
            'search': search_query,
            'limit': API_LIMIT,
            'skip': skip
        }

        try:
            print(f"ğŸ“¡ Fazendo requisiÃ§Ã£o {skip//API_LIMIT + 1}...")
            print(f"ğŸ” Query: {search_query}")
            
            response = requests.get(API_BASE_URL, params=params, timeout=30)
            print(f"ğŸ“Š Status Code: {response.status_code}")
            
            if response.status_code == 500:
                print("âŒ Erro 500 - Tentando com abordagem mais simples...")
                
                # Tentar sem filtro de data, apenas aspirin
                search_query_simple = 'patient.drug.medicinalproduct:"aspirin"'
                params_simple = {
                    'search': search_query_simple,
                    'limit': 10,  # Apenas 10 registros
                    'skip': skip
                }
                
                response_simple = requests.get(API_BASE_URL, params=params_simple, timeout=30)
                if response_simple.status_code == 200:
                    data_simple = response_simple.json()
                    results = data_simple.get('results', [])
                    if results:
                        all_results.extend(results)
                        print(f"ğŸ“¥ Encontrados {len(results)} registros (abordagem simples).")
                        break
                else:
                    print("âŒ Abordagem simples tambÃ©m falhou.")
                    break
                    
            elif response.status_code != 200:
                print(f"âŒ Erro HTTP {response.status_code}")
                break
            
            data = response.json()

            # Verificar se hÃ¡ erro
            if 'error' in data:
                error_msg = data['error']
                print(f"âš ï¸ Erro da API: {error_msg}")
                if error_msg.get('code') == 'NOT_FOUND':
                    print("â„¹ï¸ Nenhum dado encontrado para este dia.")
                    break
                else:
                    break

            results = data.get('results', [])
            
            if not results:
                print("âœ… Nenhum resultado adicional encontrado.")
                break

            all_results.extend(results)
            print(f"ğŸ“¥ PÃ¡gina {skip//API_LIMIT + 1}: {len(results)} registros. Total: {len(all_results)}")

            if len(results) < API_LIMIT:
                print("âœ… Ãšltima pÃ¡gina alcanÃ§ada.")
                break
            
            skip += API_LIMIT

        except requests.exceptions.HTTPError as e:
            print(f"âŒ Erro HTTP: {e}")
            break
        except Exception as e:
            print(f"âŒ Erro: {e}")
            break

    print(f"ğŸ¯ Busca finalizada. Total de {len(all_results)} registros brutos.")

    if not all_results:
        print("âš ï¸ Nenhum dado retornado para o dia especificado.")
        
        # Criar dados de teste para validar o pipeline
        test_data = [
            {
                'safetyreportid': f'TEST_{target_date.strftime("%Y%m%d")}_001',
                'receivedate': start_date,
                'serious': 1,
                'patient_patientsex': 1,
                'reactionmeddrapt': 'Headache'
            },
            {
                'safetyreportid': f'TEST_{target_date.strftime("%Y%m%d")}_002',
                'receivedate': start_date,
                'serious': 0,
                'patient_patientsex': 2,
                'reactionmeddrapt': 'Nausea'
            }
        ]
        df = pd.DataFrame(test_data)
        print("ğŸ§ª Usando dados de teste para validar o pipeline.")
        
    else:
        # Processar dados reais
        extracted_data = []
        for record in all_results:
            extracted_record = extract_specific_fields(record)
            if extracted_record:
                extracted_data.append(extracted_record)
        
        df = pd.DataFrame(extracted_data)
        print(f"ğŸ“Š ExtraÃ­dos {len(df)} registros com colunas especÃ­ficas.")

    # Processar e carregar para BigQuery
    if not df.empty:
        print("ğŸ‘€ Preview do DataFrame:")
        print(df.head())
        
        # Processar datas
        if 'receivedate' in df.columns:
            df['receivedate'] = pd.to_datetime(df['receivedate'], format='%Y%m%d', errors='coerce')
        
        # Carregar para BigQuery
        try:
            bq_hook = BigQueryHook(gcp_conn_id=GCP_CONN_ID, location=BQ_LOCATION, use_legacy_sql=False)
            credentials = bq_hook.get_credentials()
            destination_table = f"{BQ_DATASET}.{BQ_TABLE}"

            # Schema explÃ­cito
            table_schema = [
                {"name": "safetyreportid", "type": "STRING"},
                {"name": "receivedate", "type": "TIMESTAMP"},
                {"name": "serious", "type": "INTEGER"},
                {"name": "patient_patientsex", "type": "INTEGER"},
                {"name": "reactionmeddrapt", "type": "STRING"}
            ]

            df.to_gbq(
                destination_table=destination_table,
                project_id=GCP_PROJECT,
                if_exists="append",
                credentials=credentials,
                table_schema=table_schema,
                location=BQ_LOCATION,
                progress_bar=False,
            )
            print(f"âœ… Carga para BigQuery concluÃ­da! {len(df)} linhas carregadas.")
            return f"Successfully loaded {len(df)} records for date {start_date}"
            
        except Exception as e:
            print(f"âŒ Erro no BigQuery: {e}")
            # Verificar se a tabela existe, se nÃ£o, criar primeiro
            try:
                # Tentar criar a tabela primeiro
                test_df = pd.DataFrame([{
                    'safetyreportid': 'INIT',
                    'receivedate': pd.Timestamp.now(),
                    'serious': 0,
                    'patient_patientsex': 0,
                    'reactionmeddrapt': 'INIT'
                }])
                test_df.to_gbq(
                    destination_table=destination_table,
                    project_id=GCP_PROJECT,
                    if_exists="fail",
                    credentials=credentials,
                    table_schema=table_schema,
                    location=BQ_LOCATION,
                )
                print("âœ… Tabela criada com sucesso.")
            except Exception as create_error:
                print(f"âŒ Erro ao criar tabela: {create_error}")
            raise
    else:
        print("âš ï¸ Nenhum dado para carregar.")
        return "No data to load"

@dag(
    default_args=DEFAULT_ARGS,
    dag_id='fda_aspirin_daily',
    start_date=pendulum.datetime(2025, 9, 1, tz="UTC"),  # ComeÃ§ar em 01/09/2025
    schedule='@daily',  # Executar diariamente
    catchup=True,       # Processar dias passados
    max_active_runs=1,
    tags=['fda', 'aspirin', 'bigquery', 'daily'],
)
def fda_aspirin_daily_dag():
    fetch_and_load_fda_data()

dag = fda_aspirin_daily_dag()
