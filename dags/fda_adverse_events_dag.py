from __future__ import annotations
from airflow.decorators import dag, task
from airflow.operators.python import get_current_context
import pendulum
import requests
import pandas as pd
from airflow.providers.google.cloud.hooks.bigquery import BigQueryHook

# Configurações
GCP_PROJECT = "gen-lang-client-0010767843" 
BQ_DATASET  = "fda"     
BQ_TABLE    = "fda_data"
BQ_LOCATION = "US"      
GCP_CONN_ID = "google_cloud_default"

API_BASE_URL = "https://api.fda.gov/drug/event.json"
API_LIMIT = 100
API_MAX_RECORDS = 10000

DEFAULT_ARGS = {
    "email_on_failure": True,
    "owner": "Generated by Gemini",
}

@task
def fetch_and_load_fda_data():
    # ... (seu código existente aqui - mantém igual) ...

@dag(
    default_args=DEFAULT_ARGS,
    dag_id='fda_adverse_events_weekly',
    start_date=pendulum.datetime(2025, 1, 1, tz="UTC"),  # CORRIGIDO
    schedule='@weekly',
    catchup=True,
    max_active_runs=1,  # ADICIONADO
    tags=['fda', 'bigquery', 'api'],
)
def fda_adverse_events_dag():
    fetch_and_load_fda_data()

dag = fda_adverse_events_dag()
